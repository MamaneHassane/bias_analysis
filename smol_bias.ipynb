{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1NnpsuXsZd9YfD7VJB9VbpUz1T5Lz5Wsn",
      "authorship_tag": "ABX9TyM5C04Xv+Q9WNe3CqD5vu/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MamaneHassane/bias_analysis/blob/master/smol_bias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /root/.cache/huggingface"
      ],
      "metadata": {
        "id": "h33pIEYC1qUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP6USRtWUecV"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers evaluate langfair torch huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain-core langchain-google-vertexai"
      ],
      "metadata": {
        "id": "JDxa08vxabbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm pandas"
      ],
      "metadata": {
        "id": "GfxBXEYH-POA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "id": "KuDZY9MAUqIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from huggingface_hub import login, whoami\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "A433pA7uVxVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crows_pairs_csv = pd.read_csv(\"drive/MyDrive/Colab Notebooks/datasets/crows_pairs_anonymized.csv\")\n",
        "MODEL_NAME = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "BcoEkDWlbw6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_key = userdata.get('HF_KEY')"
      ],
      "metadata": {
        "id": "85bBTtZ3Kt1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=hf_key)\n",
        "print(whoami())"
      ],
      "metadata": {
        "id": "gTEZe4FZjSep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16).to(device)"
      ],
      "metadata": {
        "id": "_Pw_fMSqiVqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "yhqW-8-XI6nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/biais_llm/\""
      ],
      "metadata": {
        "id": "VARq4TJXAhk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le dataset\n",
        "dataset = crows_pairs_csv.to_dict(orient=\"records\")\n",
        "\n",
        "# PrÃ©parer la mÃ©trique\n",
        "bias_metric = evaluate.load(\"accuracy\")\n",
        "predictions = []\n",
        "references = []\n",
        "output_file = \"crows_pairs_results.jsonl\"\n",
        "\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    pass  # vider le fichier\n",
        "\n",
        "def compute_log_prob(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "        loss = outputs.loss.item()\n",
        "    return -loss  # plus grand = plus probable\n",
        "\n",
        "# Boucle avec Ã©valuation correcte\n",
        "for example in tqdm(dataset, desc=\"Ã‰valuation log-probabilitÃ©\"):\n",
        "    biased_sentence = example[\"sent_more\"]\n",
        "    neutral_sentence = example[\"sent_less\"]\n",
        "\n",
        "    logprob_biased = compute_log_prob(biased_sentence)\n",
        "    logprob_neutral = compute_log_prob(neutral_sentence)\n",
        "\n",
        "    # Le modÃ¨le est biaisÃ© sâ€™il prÃ©fÃ¨re la phrase stÃ©rÃ©otypÃ©e\n",
        "    model_choice = \"biased\" if logprob_biased > logprob_neutral else \"neutral\"\n",
        "\n",
        "    predictions.append(1 if model_choice == \"biased\" else 0)\n",
        "    references.append(0)\n",
        "\n",
        "    # Enregistrement JSONL\n",
        "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\n",
        "            \"neutral\": neutral_sentence,\n",
        "            \"biased\": biased_sentence,\n",
        "            \"logprob_neutral\": logprob_neutral,\n",
        "            \"logprob_biased\": logprob_biased,\n",
        "            \"model_choice\": model_choice\n",
        "        }, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Score final\n",
        "bias_score_result = bias_metric.compute(predictions=predictions, references=references)\n",
        "print(f\"\\nðŸ“Š Score final de biais : {bias_score_result['accuracy'] * 100:.2f} %\")"
      ],
      "metadata": {
        "id": "dg63Nachnnky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}